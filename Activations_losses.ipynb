{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras, tensorflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the standard activations functions used in depp neural networks and we will input a list of negative and positive numbers that we will convert to numpy arrays and output the result of the activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z = np.asarray(z)\n",
    "    f = np.exp(z)\n",
    "    sum = np.sum(np.exp(z), axis = 0)\n",
    "\n",
    "    return f/sum\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.asarray(z)\n",
    "    f = 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "    return f    \n",
    "\n",
    "def relu(z):\n",
    "    z = np.asarray(z)\n",
    "    f = np.maximum(0.0, z)\n",
    "\n",
    "    return f\n",
    "\n",
    "def leaky_relu(z):\n",
    "  z = np.asarray(z)  \n",
    "  f = [max(0.05*value,value) for value in z]\n",
    "  return np.array(f, dtype=float)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax [0.03911257 0.78559703 0.17529039] 1.0\n",
      "Sigmoid [0.26894142 0.88079708 0.62245933] 1.772197830549732\n",
      "Relu [0.  2.  0.5] 2.5\n",
      "Relu [-0.05  2.    0.5 ] 2.45\n"
     ]
    }
   ],
   "source": [
    "z = [-1, 2, 0.5]\n",
    "softmax_z = softmax(z)\n",
    "sigmoid_z = sigmoid(z)\n",
    "relu_z = relu(z)\n",
    "leaky_relu_z = leaky_relu(z)\n",
    "\n",
    "print('Softmax',softmax_z, np.sum(softmax_z, axis = 0))\n",
    "print('Sigmoid',sigmoid_z, np.sum(sigmoid_z, axis = 0))\n",
    "print('Relu',relu_z, np.sum(relu_z, axis = 0))    \n",
    "print('Relu',leaky_relu_z, np.sum(leaky_relu_z, axis = 0))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import these function definitions from Keras and compare the two outputs, first we have to convert our list into a numpy array and then to a tensorflow format tensor that can then be passed into it for getting back the activation function outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax tf.Tensor([0.03911257 0.78559703 0.17529039], shape=(3,), dtype=float64) 1.0\n",
      "Sigmoid tf.Tensor([0.26894142 0.88079708 0.62245933], shape=(3,), dtype=float64) 1.772197830549732\n",
      "Relu tf.Tensor([0.  2.  0.5], shape=(3,), dtype=float64) 2.5\n",
      "Relu tf.Tensor([-0.3  2.   0.5], shape=(3,), dtype=float32) 2.2\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K \n",
    "zarr = tensorflow.convert_to_tensor(np.asarray(z))\n",
    "keras_softmax_z = K.softmax(zarr)\n",
    "keras_sigmoid_z = K.sigmoid(zarr)\n",
    "keras_relu_z = K.relu(zarr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Softmax',keras_softmax_z, np.sum(keras_softmax_z, axis = 0))\n",
    "print('Sigmoid',keras_sigmoid_z, np.sum(keras_sigmoid_z, axis = 0))\n",
    "print('Relu',keras_relu_z, np.sum(keras_relu_z, axis = 0))    \n",
    "print('Relu',keras_leaky_relu_z, np.sum(keras_leaky_relu_z, axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('naparienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e140276ae15c1be7b597ddfede76c3757c35dc6a4240f18994000df39384733e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
